{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c39ddd4-0108-44b4-a954-143d06fff4bd",
   "metadata": {},
   "source": [
    "# Integrating External Recommenders with RAG for Context-Aware Conversational Movie Recommendation (Baseline)\n",
    "\n",
    "In this project, we developed a conversational movie recommender that integrates Retrieval-Augmented Generation (RAG) architecture with specialized external recommenders trained on movie datasets. Implemented as the final project in Recommender Systems course in Toronto Metropolitan University.\n",
    "\n",
    "By combining the reasoning capabilities of LLMs with domain-specific recommenders, we created a conversational recommender that considers context to provide accurate recommendations. We implemented and compared the performance of the system using three external domain recommenders: 1) a BERT-based Transformer with a trainable recommender head, 2) a Relational Graph Convolutional Neural Network (RGCN), and 3) Neural Collaborative Filtering (NCF), all trained on the INSPIRED movie dataset.\n",
    "\n",
    "We implemented the following models:\n",
    "\n",
    "* LLM + RAG (Baseline)\n",
    "* [LLM + RAG + RGCN](./RGCN.ipynb)\n",
    "* LLM + RAG + NCF\n",
    "* LLM + RAG + Transformer\n",
    "\n",
    "In this notebook, the *LLM + RAG (Baseline)* model is implemented and used to connect the external recommenders to the baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ade436-9b3f-4a5c-b61c-af7ce77ba61c",
   "metadata": {},
   "source": [
    "## Environment Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e05eb1b-492c-4b7a-9d79-85a88c25a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\91953\\Documents\\GitHub\\RAG-Movie-CRS\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function:\n",
    "    - Check Current Working Directory\n",
    "    - Move to Correct Directory\n",
    "'''\n",
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47eb83b-7d28-4cc3-a727-528f4bcde1c7",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a2864c-ed76-4bfb-a3a9-fe6e2e36c842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: ollama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: llama-index-core in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.14.8)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.8.4)\n",
      "Requirement already satisfied: llama-index-llms-ollama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: chromadb in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (1.3.5)\n",
      "Requirement already satisfied: pypdf in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (6.4.0)\n",
      "Requirement already satisfied: nbimport in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (0.0.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (4.57.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (1.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (0.24.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 15)) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from ollama->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from ollama->-r requirements.txt (line 2)) (2.12.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from tqdm->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2025.10.0)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.9.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (10.3.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core->-r requirements.txt (line 4)) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.22.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\91953\\anaconda3\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: pytest-asyncio>=0.23.8 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-embeddings-ollama->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (3.11.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core->-r requirements.txt (line 4)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core->-r requirements.txt (line 4)) (2025.11.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 12)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 12)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 13)) (1.14.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\91953\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\91953\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\91953\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.28.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\91953\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core->-r requirements.txt (line 4)) (8.3.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\91953\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\91953\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\91953\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (6.33.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8)) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 8)) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama->-r requirements.txt (line 2)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: pytest<10,>=8.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (9.0.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest<10,>=8.2->pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest<10,>=8.2->pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest<10,>=8.2->pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core->-r requirements.txt (line 4)) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 8)) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27->ollama->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (3.5.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core->-r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753acff-d903-4da6-83eb-e2fc8641220b",
   "metadata": {},
   "source": [
    "### RAG, LLM, Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93160c4-d716-4b38-a400-7fc23d8a2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import subprocess\n",
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d93570-cfd3-4524-8c5f-e504ecacd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    request_timeout=300.0,\n",
    ")\n",
    "\n",
    "# Initialize the LLM with optimized settings\n",
    "llm = Ollama(\n",
    "    model=\"llama3.2:1B\",\n",
    "    request_timeout=300.0,\n",
    "    temperature=0.1,  # Keep the model predictable\n",
    "    additional_kwargs={\"num_gpu\": 0}  # Forcing CPU usage\n",
    ")\n",
    "\n",
    "# Set global configurations\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab9c9a-0588-4d21-b930-e7876b4a6b22",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375fdbb0-77aa-4baa-a2ee-6bc98a2d0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions:\n",
    "    - Load INSPIRED dataset from TSV \n",
    "    - Convert to documents\n",
    "\n",
    "Args:\n",
    "    - data_path: Path to the TSV file\n",
    "    - max_rows: Maximum number of rows to load (None = load all rows)\n",
    "'''\n",
    "\n",
    "def load_inspired_dataset(data_path, max_rows=None):\n",
    "    \n",
    "    if not Path(data_path).exists():\n",
    "        raise FileNotFoundError(f\"INSPIRED dataset not found at '{data_path}'\")\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    # First pass: count total rows for progress bar\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        total_rows = sum(1 for _ in f) - 1  # Subtract header row\n",
    "\n",
    "    # If not using all rows, select min of total and max\n",
    "    # kept for debugging\n",
    "    if max_rows is not None:\n",
    "        total_rows = min(total_rows, max_rows)\n",
    "    \n",
    "    # 2nd pass: Load the TSV data\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter='\\t')\n",
    "        \n",
    "        for idx, row in enumerate(tqdm(reader, total=total_rows, desc=\"Loading data\")):\n",
    "            # Stop if reached max_rows\n",
    "            if max_rows is not None and idx >= max_rows:\n",
    "                break\n",
    "                \n",
    "            # Extract conversation information from TSV\n",
    "            dialog_id = row.get('dialog_id', '')\n",
    "            turn_id = row.get('turn_id', '')\n",
    "            utterance = row.get('utterance', '')\n",
    "            speaker = row.get('speaker', '')\n",
    "            movie_name = row.get('movie_name', '')\n",
    "            \n",
    "            # Create document text\n",
    "            doc_text = f\"Speaker: {speaker}\\nUtterance: {utterance}\\n\"\n",
    "            \n",
    "            if movie_name:\n",
    "                doc_text += f\"Movie mentioned: {movie_name}\\n\"\n",
    "            \n",
    "            # Create metadata\n",
    "            metadata = {\n",
    "                \"dialog_id\": dialog_id,\n",
    "                \"turn_id\": turn_id,\n",
    "                \"speaker\": speaker,\n",
    "                \"movie_name\": movie_name if movie_name else \"None\"\n",
    "            }\n",
    "            \n",
    "            # Create Document object\n",
    "            doc = Document(text=doc_text, metadata=metadata)\n",
    "            documents.append(doc)\n",
    "    \n",
    "    print(f\"Loaded {len(documents)} out of {total_rows} conversational turns from INSPIRED dataset\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240deead-b273-4a61-afc6-0929a0fcfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions:\n",
    "    - Load the unprocessed INSPIRED movie database for reference\n",
    "Args:\n",
    "    - dataset_dir: Directory of the TSV file\n",
    "'''\n",
    "\n",
    "def load_movie_database(dataset_dir=\"data\"):\n",
    "    \n",
    "    movie_db_path = Path(dataset_dir) / \"raw\" / \"movie_database.tsv\"\n",
    "    \n",
    "    if not movie_db_path.exists():\n",
    "        print(f\"Movie database not found at {movie_db_path}\")\n",
    "        return {}\n",
    "    \n",
    "    movies = {}\n",
    "    with open(movie_db_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            movie_id = row.get('movieId', '')\n",
    "            movies[movie_id] = row\n",
    "    \n",
    "    print(f\"Loaded {len(movies)} movies from FULL movie database\")\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15d594-c387-4054-a287-7ca534fc58ab",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1fdaa-add7-46aa-bafb-741daff6d08b",
   "metadata": {},
   "source": [
    "### Create Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93467a66-007e-40c0-bda4-2d928ec924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "    - Load INSPIRED dataset\n",
    "    - Create vector index\n",
    "\n",
    "Args:\n",
    "    - dataset_dir: Directory containing the dataset\n",
    "    - split: Which split to use (train, dev, test)\n",
    "    - max_rows: Maximum number of rows to load (None for all rows)\n",
    "    - load_movie_db: Whether to load movie database (needed for external recommenders)\n",
    "\n",
    "Returns:\n",
    "    - index: VectorStoreIndex for RAG\n",
    "    - movie_db: Movie database (if load_movie_db=True), else None\n",
    "'''\n",
    "\n",
    "def load_and_index_documents(dataset_dir=\"data\", split=\"train\", max_rows=None, load_movie_db=True):\n",
    "        \n",
    "    # Construct path to the data file \n",
    "    data_path = Path(dataset_dir) / \"processed\" / f\"{split}.tsv\"\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Data file not found at {data_path}.\\nCheck for typos in file path.\"\n",
    "        )\n",
    "    \n",
    "    # Load INSPIRED documents with max_rows limit\n",
    "    docs = load_inspired_dataset(data_path, max_rows=max_rows)\n",
    "    \n",
    "    if not docs:\n",
    "        raise ValueError(\"No documents loaded from INSPIRED dataset\")\n",
    "    \n",
    "    # load movie database for reference\n",
    "    # Used by external recommenders\n",
    "    movie_db = load_movie_database(dataset_dir)\n",
    "    \n",
    "    # Load documents, then\n",
    "    # Build vector index from documents\n",
    "    # Using the Embed model\n",
    "    print(\"Building vector index...\")\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        docs, \n",
    "        embed_model=embed_model,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    return index, movie_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395c9f2-ec6f-456f-8b65-46ce6a8b1f0e",
   "metadata": {},
   "source": [
    "### Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b766a5b6-32c7-499a-a590-83cb225d56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "    - Create query engine with specified retrieval parameters\n",
    "'''\n",
    "\n",
    "def create_query_engine(index, similarity_top_k=5):\n",
    "    \n",
    "    query_engine = index.as_query_engine(\n",
    "        llm=llm,\n",
    "        similarity_top_k=similarity_top_k,\n",
    "        response_mode=\"compact\", # Reduce token usage\n",
    "        streaming=True\n",
    "    )\n",
    "    \n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76920e49-6e58-43d3-8fac-92967af05a0f",
   "metadata": {},
   "source": [
    "### Adapt External Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702aca5-eb32-4661-b4ab-98f28ceadc0c",
   "metadata": {},
   "source": [
    "### Interactive Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea846df-d92c-445b-8029-ba30720b610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interactive conversation with history tracking\n",
    "'''\n",
    "def interactive_conversation_with_history():\n",
    "    \n",
    "    try:\n",
    "        # Load documents and create index\n",
    "        print(\"\\nLoading INSPIRED dataset...\")\n",
    "        index, _ = load_and_index_documents(split=\"train\", max_rows=20)\n",
    "        \n",
    "        # Create chat engine instead of query engine\n",
    "        # query_engine: Stateless - each query is independent\n",
    "        # chat_engine: Stateful - remembers conversation history \n",
    "        #              better for multi-turn conversations\n",
    "        chat_engine = index.as_chat_engine(\n",
    "            llm=llm,\n",
    "            similarity_top_k=5,\n",
    "            chat_mode=\"context\"  # Use context mode for history\n",
    "        )\n",
    "        \n",
    "        \n",
    "        print(\"|| MovieCRS is Ready ||\")\n",
    "        \n",
    "        print(\"\\nYou can now ask for movie recommendations.\")\n",
    "        print(\"Type 'quit', 'exit', or 'q' to end the conversation.\\n\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'q', 'bye']:\n",
    "                print(\"\\nMovieCRS: Exiting...\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Use chat() instead of query() - it handles history automatically\n",
    "                print(\"\\nMovieCRS: \", end=\"\", flush=True)\n",
    "                response = chat_engine.chat(user_input)\n",
    "                \n",
    "                # Print only the response text\n",
    "                print(f\"{response.response}\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {str(e)}\\n\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"System Error: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dbf603-dce1-4b36-9738-c79df2261cb3",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c777faf-fe1f-4a14-aa16-7752c781dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RAG Pipeline with INSPIRED Dataset...\n",
      "\n",
      "Loading INSPIRED dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 20/20 [00:00<00:00, 19930.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 turns from INSPIRED dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 movies from movie database\n",
      "Building vector index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc496b87d760431c962c9ad845aa71f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7a77f7af744dfb204af86b563eef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|| MovieCRS is Ready ||\n",
      "\n",
      "You can now ask for movie recommendations.\n",
      "Type 'quit', 'exit', or 'q' to end the conversation.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  do not ask any questions, only recommend. I like horror but I want to watch romance now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MovieCRS: I'd be happy to help you find a new movie that combines horror and romance.\n",
      "\n",
      "Considering your interest in horror movies, here are some recommendations that might also appeal to you:\n",
      "\n",
      "1. **The Babadook** (2014) - A psychological horror-thriller about a mother and son who are haunted by a supernatural entity.\n",
      "2. **It Follows** (2014) - A supernatural horror film about a young woman who is pursued by a relentless, shape-shifting entity.\n",
      "3. **A Dark Song** (2016) - A supernatural horror movie about a grieving mother who rents a remote house in order to perform a ritual to contact her deceased son.\n",
      "\n",
      "If you're looking for something a bit more lighthearted and romantic, here are some recommendations:\n",
      "\n",
      "1. **The Love Witch** (2016) - A campy, retro-inspired horror-comedy that's also a romance.\n",
      "2. **Starry Eyes** (2014) - A body horror film with a strong romantic subplot.\n",
      "3. **Raw** (2016) - A French-Belgian horror film about a young vegetarian who becomes a carnivore after a near-death experience.\n",
      "\n",
      "Let me know if any of these recommendations appeal to you, or if you'd like more suggestions!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Starting RAG Pipeline with INSPIRED Dataset...\")\n",
    "    \n",
    "    # Start interactive conversation with history\n",
    "    success = interactive_conversation_with_history()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\nSystem failed to start.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b9987-6e7d-43af-94c5-afda31721d8a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84320e56-f528-4e81-b0f3-4ed66ee7f34f",
   "metadata": {},
   "source": [
    "### Standard Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846c143-d2ec-46a1-bb5c-a50ff1370ce9",
   "metadata": {},
   "source": [
    "### Contextual Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6eea67-9f67-46e2-8941-d0983ede6092",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672b5ce-a84c-441f-8ceb-ea10d1a64a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

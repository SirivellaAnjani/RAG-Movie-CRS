{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c39ddd4-0108-44b4-a954-143d06fff4bd",
   "metadata": {},
   "source": [
    "# Integrating Transformer as an External Recommenders\n",
    "\n",
    "In this notebook, the LLM + RAG + Transformer model is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ade436-9b3f-4a5c-b61c-af7ce77ba61c",
   "metadata": {},
   "source": [
    "## Environment Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e05eb1b-492c-4b7a-9d79-85a88c25a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\91953\\JupyterNotebooks\\RAG-2-optimized\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Check Current Working Directory\n",
    "'''\n",
    "import os\n",
    "\n",
    "# Change Working Directory if needed \n",
    "os.chdir(\"C:/Users/91953/JupyterNotebooks/RAG-2-optimized\")\n",
    "\n",
    "# Check if in correct directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47eb83b-7d28-4cc3-a727-528f4bcde1c7",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a2864c-ed76-4bfb-a3a9-fe6e2e36c842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: ollama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: llama-index-core in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.14.8)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.8.4)\n",
      "Requirement already satisfied: llama-index-llms-ollama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: chromadb in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (1.3.5)\n",
      "Requirement already satisfied: pypdf in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (6.4.0)\n",
      "Requirement already satisfied: nbimport in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (0.0.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (4.57.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (1.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (0.24.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\91953\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 15)) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from ollama->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from ollama->-r requirements.txt (line 2)) (2.12.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\91953\\anaconda3\\lib\\site-packages (from tqdm->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2025.10.0)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.9.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (10.3.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core->-r requirements.txt (line 4)) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.22.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\91953\\anaconda3\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: pytest-asyncio>=0.23.8 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from llama-index-embeddings-ollama->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (3.11.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from chromadb->-r requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core->-r requirements.txt (line 4)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core->-r requirements.txt (line 4)) (2025.11.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 12)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 12)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 13)) (1.14.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\91953\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\91953\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\91953\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.28.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\91953\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core->-r requirements.txt (line 4)) (8.3.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\91953\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\91953\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\91953\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (6.33.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8)) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 8)) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama->-r requirements.txt (line 2)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: pytest<10,>=8.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (9.0.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest<10,>=8.2->pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest<10,>=8.2->pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from pytest<10,>=8.2->pytest-asyncio>=0.23.8->llama-index-embeddings-ollama->-r requirements.txt (line 5)) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core->-r requirements.txt (line 4)) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 8)) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27->ollama->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (3.5.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core->-r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91953\\anaconda3\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753acff-d903-4da6-83eb-e2fc8641220b",
   "metadata": {},
   "source": [
    "### RAG, LLM, Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93160c4-d716-4b38-a400-7fc23d8a2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import subprocess\n",
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# Import the transformer recommender\n",
    "from scripts.transformer_recommender import TransformerRecommender, INSPIREDDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d93570-cfd3-4524-8c5f-e504ecacd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    request_timeout=300.0,\n",
    ")\n",
    "\n",
    "# Initialize the LLM with optimized settings\n",
    "llm = Ollama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    request_timeout=300.0,\n",
    "    temperature=0.7,\n",
    "    additional_kwargs={\"num_gpu\": 0}\n",
    ")\n",
    "\n",
    "# Set global configurations\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "# Global transformer model and processor\n",
    "transformer_model = None\n",
    "data_processor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab9c9a-0588-4d21-b930-e7876b4a6b22",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375fdbb0-77aa-4baa-a2ee-6bc98a2d0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions:\n",
    "    - Load INSPIRED dataset from TSV \n",
    "    - Convert to documents\n",
    "\n",
    "Args:\n",
    "    - data_path: Path to the TSV file\n",
    "    - max_rows: Maximum number of rows to load (None = load all rows)\n",
    "'''\n",
    "\n",
    "def load_inspired_dataset(data_path, max_rows=None):\n",
    "    \n",
    "    if not Path(data_path).exists():\n",
    "        raise FileNotFoundError(f\"INSPIRED dataset not found at '{data_path}'.\")\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    # First pass: count total rows for progress bar\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        total_rows = sum(1 for _ in f) - 1  # Subtract header row\n",
    "    \n",
    "    if max_rows is not None:\n",
    "        total_rows = min(total_rows, max_rows)\n",
    "    \n",
    "    # Load the TSV data\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter='\\t')\n",
    "        \n",
    "        for idx, row in enumerate(tqdm(reader, total=total_rows, desc=\"Loading data\")):\n",
    "            # Stop if we've reached max_rows\n",
    "            if max_rows is not None and idx >= max_rows:\n",
    "                break\n",
    "                \n",
    "            # Extract conversation information from TSV\n",
    "            dialog_id = row.get('dialog_id', '')\n",
    "            turn_id = row.get('turn_id', '')\n",
    "            utterance = row.get('utterance', '')\n",
    "            speaker = row.get('speaker', '')\n",
    "            movie_name = row.get('movie_name', '')\n",
    "            \n",
    "            # Create document text\n",
    "            doc_text = f\"Speaker: {speaker}\\nUtterance: {utterance}\\n\"\n",
    "            \n",
    "            if movie_name:\n",
    "                doc_text += f\"Movie mentioned: {movie_name}\\n\"\n",
    "            \n",
    "            # Create metadata\n",
    "            metadata = {\n",
    "                \"dialog_id\": dialog_id,\n",
    "                \"turn_id\": turn_id,\n",
    "                \"speaker\": speaker,\n",
    "                \"movie_name\": movie_name if movie_name else \"None\"\n",
    "            }\n",
    "            \n",
    "            # Create Document object\n",
    "            doc = Document(text=doc_text, metadata=metadata)\n",
    "            documents.append(doc)\n",
    "    \n",
    "    print(f\"Loaded {len(documents)} turns from INSPIRED dataset\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240deead-b273-4a61-afc6-0929a0fcfe06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef load_movie_database(dataset_dir=\"data\"):\\n\\n    movie_db_path = Path(dataset_dir) / \"raw\" / \"movie_database.tsv\"\\n\\n    if not movie_db_path.exists():\\n        print(f\"Movie database not found at {movie_db_path}\")\\n        return {}\\n\\n    movies = {}\\n    with open(movie_db_path, \\'r\\', encoding=\\'utf-8\\') as f:\\n        reader = csv.DictReader(f, delimiter=\\'\\t\\')\\n        for row in reader:\\n            movie_id = row.get(\\'movieId\\', \\'\\')\\n            movies[movie_id] = row\\n\\n    print(f\"Loaded {len(movies)} movies from movie database\")\\n    return movies\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Customized Function is created in the external recommender python file\n",
    "\n",
    "Functions:\n",
    "    - Load the unprocessed INSPIRED movie database for reference\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "def load_movie_database(dataset_dir=\"data\"):\n",
    "    \n",
    "    movie_db_path = Path(dataset_dir) / \"raw\" / \"movie_database.tsv\"\n",
    "    \n",
    "    if not movie_db_path.exists():\n",
    "        print(f\"Movie database not found at {movie_db_path}\")\n",
    "        return {}\n",
    "    \n",
    "    movies = {}\n",
    "    with open(movie_db_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            movie_id = row.get('movieId', '')\n",
    "            movies[movie_id] = row\n",
    "    \n",
    "    print(f\"Loaded {len(movies)} movies from movie database\")\n",
    "    return movies\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15d594-c387-4054-a287-7ca534fc58ab",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1fdaa-add7-46aa-bafb-741daff6d08b",
   "metadata": {},
   "source": [
    "### Create Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93467a66-007e-40c0-bda4-2d928ec924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "    - Load INSPIRED dataset\n",
    "    - Create vector index\n",
    "\n",
    "Args:\n",
    "    - dataset_dir: Directory containing the dataset\n",
    "    - split: Which split to use (train, dev, test)\n",
    "    - max_rows: Maximum number of rows to load (None for all rows)\n",
    "    - load_movie_db: Whether to load movie database (needed for external recommenders)\n",
    "\n",
    "Returns:\n",
    "    - index: VectorStoreIndex for RAG\n",
    "'''\n",
    "\n",
    "def load_and_index_documents(dataset_dir=\"data\", split=\"train\", max_rows=None):\n",
    "        \n",
    "    # Construct path to the data file \n",
    "    data_path = Path(dataset_dir) / \"processed\" / f\"{split}.tsv\"\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Data file not found at {data_path}. \\nCheck for typos.\"\n",
    "        )\n",
    "    \n",
    "    # Load INSPIRED documents with max_rows limit\n",
    "    docs = load_inspired_dataset(data_path, max_rows=max_rows)\n",
    "    \n",
    "    if not docs:\n",
    "        raise ValueError(\"No documents loaded from INSPIRED dataset\")\n",
    "    \n",
    "    # load movie database for reference\n",
    "    # Used by external recommenders\n",
    "    #movie_db = INSPIREDDataProcessor.load_movie_database(dataset_dir)\n",
    "    \n",
    "    # Load documents, then\n",
    "    # Build vector index from documents\n",
    "    print(\"Building vector index...\")\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        docs, \n",
    "        embed_model=embed_model,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395c9f2-ec6f-456f-8b65-46ce6a8b1f0e",
   "metadata": {},
   "source": [
    "### Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b766a5b6-32c7-499a-a590-83cb225d56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "    - Create query engine with specified retrieval parameters\n",
    "'''\n",
    "\n",
    "def create_query_engine(index, similarity_top_k=5):\n",
    "    \n",
    "    query_engine = index.as_query_engine(\n",
    "        llm=llm,\n",
    "        similarity_top_k=similarity_top_k,\n",
    "        response_mode=\"compact\",\n",
    "        streaming=True\n",
    "    )\n",
    "    \n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76920e49-6e58-43d3-8fac-92967af05a0f",
   "metadata": {},
   "source": [
    "### Adapt External Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f9a3f1-6d5b-4724-b297-5933df7f54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "    - Initialize the transformer recommender\n",
    "    - Train the transformer recommender\n",
    "'''\n",
    "\n",
    "def initialize_transformer_model(dataset_dir=\"data\"):\n",
    "\n",
    "    global transformer_model, data_processor\n",
    "    \n",
    "    print(\"|| INITIALIZING TRANSFORMER RECOMMENDER ||\")\n",
    "\n",
    "    # Load movie database\n",
    "    data_processor = INSPIREDDataProcessor(dataset_dir)\n",
    "    movie_id_map, movie_name_map = data_processor.load_movie_database()\n",
    "    \n",
    "    # Initialize model\n",
    "    transformer_model = TransformerRecommender(num_movies=len(movie_id_map))\n",
    "    \n",
    "    # TODO: Add training code here to train from scratch\n",
    "    # For now, we'll use it in inference mode (random initialization)\n",
    "    \n",
    "    print(\"Transformer model initialized\")\n",
    "    return transformer_model, data_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90691ad4-2621-4284-88f0-ae29cb552598",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get top-k movie recommendations from transformer\n",
    "'''\n",
    "def get_transformer_recommendations(conversation_history, top_k=3):\n",
    "    \n",
    "    if transformer_model is None or data_processor is None:\n",
    "        raise ValueError(\"Transformer model not initialized\")\n",
    "    \n",
    "    # Combine conversation history into single text\n",
    "    conversation_text = \" \".join(conversation_history[-6:])  # Last 3 exchanges\n",
    "    \n",
    "    # Get recommendations from transformer\n",
    "    recommendations = transformer_model.predict_top_k(\n",
    "        conversation_text,\n",
    "        data_processor.movie_name_map,\n",
    "        k=top_k\n",
    "    )\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702aca5-eb32-4661-b4ab-98f28ceadc0c",
   "metadata": {},
   "source": [
    "### Interactive Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea846df-d92c-445b-8029-ba30720b610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interactive conversation with transformer + LLM pipeline\n",
    "using history\n",
    "'''\n",
    "\n",
    "def interactive_conversation_with_transformer():\n",
    "    \n",
    "    try:\n",
    "        # Load documents and create index\n",
    "        print(\"\\nLoading INSPIRED dataset...\")\n",
    "        index = load_and_index_documents(split=\"train\", max_rows=100)\n",
    "        \n",
    "        # Initialize transformer model\n",
    "        transformer_model, data_processor = initialize_transformer_model()\n",
    "        \n",
    "        # Create chat engine\n",
    "        chat_engine = index.as_chat_engine(\n",
    "            llm=llm,\n",
    "            similarity_top_k=5,\n",
    "            chat_mode=\"context\"\n",
    "        )\n",
    "        \n",
    "        print(\"|| MovieCRS ready! ||\")\n",
    "        print(\"(Using Transformer + LLM Pipeline)\")\n",
    "\n",
    "        print(\"\\nYou can now ask for movie recommendations.\")\n",
    "        print(\"Type 'quit', 'exit', or 'q' to end the conversation.\\n\")\n",
    "        \n",
    "        conversation_history = []\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'q', 'bye']:\n",
    "                print(\"\\nMovieCRS: Bye.\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Add user input to history\n",
    "                conversation_history.append(f\"User: {user_input}\")\n",
    "                \n",
    "                # STEP 1: Get transformer recommendations\n",
    "                print(\"\\n[Generating recommendations...]\", end=\"\", flush=True)\n",
    "                transformer_recs = get_transformer_recommendations(conversation_history, top_k=5)\n",
    "                \n",
    "                # Format transformer recommendations\n",
    "                rec_text = \"\\n\".join([\n",
    "                    f\"- {rec['movie_name']} (score: {rec['score']:.3f})\"\n",
    "                    for rec in transformer_recs[:5]  # Top 5\n",
    "                ])\n",
    "                \n",
    "                # STEP 2: Create enhanced query with transformer recommendations\n",
    "                enhanced_query = f\"\"\"\n",
    "User query: \n",
    "{user_input}\n",
    "\n",
    "Top recommended movies from our recommendation system:\n",
    "{rec_text}\n",
    "\n",
    "Based on the user's preferences and these recommendations, provide a natural, \n",
    "conversational response suggesting appropriate movies.\n",
    "\"\"\"\n",
    "                \n",
    "                # STEP 3: Get LLM response\n",
    "                print(\"\\r[Generating response...]    \", end=\"\", flush=True)\n",
    "                response = chat_engine.chat(enhanced_query)\n",
    "                \n",
    "                print(\"\\nMovieCRS: \", end=\"\", flush=True)\n",
    "                print(f\"{response.response}\\n\")\n",
    "                \n",
    "                # Add to history\n",
    "                conversation_history.append(f\"MovieCRS: {response.response}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError: {str(e)}\\n\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"System Error: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dbf603-dce1-4b36-9738-c79df2261cb3",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c777faf-fe1f-4a14-aa16-7752c781dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Transformer + LLM Pipeline with INSPIRED Dataset...\n",
      "\n",
      "Loading INSPIRED dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 100/100 [00:00<00:00, 17050.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 turns from INSPIRED dataset\n",
      "Building vector index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de73fc8f77794477931c2215c2e80409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3149d0622eb845b1ae5c2c3d1415c18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|| INITIALIZING TRANSFORMER RECOMMENDER ||\n",
      "Loading 17869 movies from database...\n",
      "Loaded 16764 movies\n",
      "Transformer model initialized\n",
      "|| MovieCRS ready! ||\n",
      "(Using Transformer + LLM Pipeline)\n",
      "\n",
      "You can now ask for movie recommendations.\n",
      "Type 'quit', 'exit', or 'q' to end the conversation.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  i like horror but not today, now i want romance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Generating response...]    ..]\n",
      "MovieCRS: Speaker: RECOMMENDER\n",
      "Utterance:\n",
      "\n",
      "Hey there! Since you're in the mood for something different from horror movies today, I've got some romance movie suggestions that might interest you. \n",
      "\n",
      "Based on your preferences and my previous recommendations, here are a few options to consider:\n",
      "\n",
      "- Steel (1997) is a romantic thriller starring Bruce Willis and Angelina Jolie.\n",
      "- Fire and Ice (2016) is a drama film based on the novel \"Fire and Ice\" by Ayn Rand.\n",
      "- The Covenant (2003) has a unique storyline that might appeal to horror fans looking for something different.\n",
      "\n",
      "Give these movies a try, or let me know if you'd like more recommendations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Starting Transformer + LLM Pipeline with INSPIRED Dataset...\")\n",
    "    \n",
    "    # Start interactive conversation with transformer\n",
    "    success = interactive_conversation_with_transformer()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\nSystem failed to start. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b9987-6e7d-43af-94c5-afda31721d8a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84320e56-f528-4e81-b0f3-4ed66ee7f34f",
   "metadata": {},
   "source": [
    "### Standard Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846c143-d2ec-46a1-bb5c-a50ff1370ce9",
   "metadata": {},
   "source": [
    "### Contextual Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6eea67-9f67-46e2-8941-d0983ede6092",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672b5ce-a84c-441f-8ceb-ea10d1a64a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
